---
title: 'Breaking down FOMC Minutes: Sentiment indicators'
author: Christoffer Nordenlöw
date: '2021-01-10'
slug: []
categories:
  - Federal Reserve
  - FOMC
  - Minutes
  - Python
  - R
tags:
  - Federal Reserve
  - Minutes
  - FOMC
  - Python
  - R
description: 'Breaking down FOMC Minutes'
topics: []
---




```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE)
```




```{r, echo=FALSE, messages=FALSE,warning=FALSE,include=FALSE}

library(tidyverse)
library(lubridate)
library(slider)
library(dplyr, warn.conflicts = FALSE)
library(lubridate, warn.conflicts = FALSE)


library(ggrepel)




###source plots
source('C:\\Users\\chris\\Documents\\Python\\text-mining-fomc\\r_plots.R')


#setting overlaps for ggrepel
options(ggrepel.max.overlaps = Inf)

df <- read.table(
"https://raw.githubusercontent.com/cnordenlow/text-mining-fomc/main/Data/fomcMinutesSummary.csv",  ##på detta sätt läser den ur aktuell mapp
  sep=",", header=TRUE)


#Change dates
df <- df %>%
  mutate(date = as.Date(gsub("\\D", "", date), format = "%Y%m%d"))


#arrange
df <- arrange(df, date)



#numrera antal protokoll
temp <- df%>%
  select(date) %>%
  distinct() %>%
  mutate(num = 1:n())

df <- merge(df, temp, by = "date", all.x = TRUE)


###sliding mean
df <- df  %>%
  group_by(subject, additional) %>% 
  mutate(avg_st = slide_index_dbl(frequency, num, mean, .before=3, .after=-1,.complete=T)) %>% ##dont include the current
  mutate(avg_lt = mean(frequency))%>%
  mutate(avg_st_share = slide_index_dbl(frequency_share, num, mean, .before=3, .after=-1,.complete=T))%>%
  mutate(avg_lt_share = mean(frequency_share))%>%
  mutate(ma_3m = slide_index_dbl(frequency, num, mean, .before=2, .after=0, .complete=T))%>%
  mutate(ma_3m_share = slide_index_dbl(frequency_share, num, mean, .before=2, .after=0, .complete=T))


#exclude first three rows to only include when 3m_moving is on
df <-df %>%
  filter(num > 3)

#one minute lag
df <- df %>%
  group_by(subject, additional) %>%
  mutate(previous = lag(frequency, n = 1, default = NA)) %>%
  mutate(previous_share = lag(frequency_share, n = 1, default = NA))



df <- df %>%
  mutate(chg_previous = frequency - previous)%>%
  mutate(chg_avg_st = frequency - avg_st)%>%
  mutate(chg_avg_lt = frequency - avg_lt)%>%
  mutate(chg_previous_share = frequency_share - previous_share)%>%
  mutate(chg_avg_st_share = frequency_share - avg_st_share)%>%
  mutate(chg_avg_lt_share = frequency_share - avg_lt_share)

  





###fed funds rate


df2 <- read.table(
  "https://raw.githubusercontent.com/cnordenlow/text-mining-fomc/main/Data/fedFundsRate.csv", 
  sep=",", header=TRUE)


#Change dates
df2 <- df2 %>%
  mutate(date = as.Date(gsub("\\D", "", date), format = "%Y%m%d"))


#arrange
df2 <- arrange(df2, date)

df2 <- df2%>%
  filter(bound == "lower_bound")%>%
  select(-bound)



df <- merge(df, df2, by ="date", all.x =  TRUE)

df <- as.data.frame(df)
df[is.na(df)] <- 0




```

```{r, echo=FALSE, results='asis'}
#https://bookdown.org/yihui/rmarkdown-cookbook/results-asis.html
#This is for writing markdown text but grabbing the date from the dataset
header = paste("## Text mining FOMC Minutes", max(df$date))
cat(header)

## Text Mining the Fed 

```
*Sentiment has clearly picked up during the fall. One interesting point is that there is a positive net sentiment index, but still below average intensifier index which indicates that the negative words are more connected with intensifier words then what positive words are.
Mapping Feds mind gives further juice on this as topics/words like strong, expansion are up and coming while decline, weak are well below its short and long term average. Recovery is fading which should be normal with that in mind: first we have decline -> followed by recovery -> which leads to strong/expansion. During 2020 we had it all. 
Al together the economy did recover well during the fall but we should´t jump the bandwagon yet. The spread of Coronavirus have intensified since the meeting even though vaccination process has begun (which news of was probably driving some of the Fed-happines). Uncerntainty is real, which also shows in the plots.*


**Short explanation of the indexes.**

**Net sentiment index** shows the net sum of positive words minus negative words for each Minutes.

**Intensifier index** shows the sum of positive minus negative words together with intensifier words like "extremely",
"exceptionally" etc. This index shows the depth of the sentiment.

**(Strong-Weak)/Moderate index** shows the net of words like "strong, stronger" minus "weak, weaker" divided by word like "moderate".

**Mapping Feds mind** gives a feeling for which selected words/topics that are hot and not.

Latest report can be found *[here](https://cnordenlow.github.io/text-mining-fomc/)*. 

Code available on *[github](https://github.com/cnordenlow/text-mining-fomc)*.


```{r, echo=FALSE, messages=FALSE, warning=FALSE}

#plot spread, average sentiment trending down

temp <- df %>%
  filter(category == "sentiment")%>%
  filter(subject == "net_sentiment")%>%
 # mutate(sign = if_else(chg_avg >= 0, "Positive", "Negative"))  %>%
#  as.data.frame(temp)%>%
  pivot_longer(-c("category", "subject", "additional", "date"), values_to = "values")%>%
  filter(name %in% c("chg_avg_lt_share"))%>%
  mutate(change_positive = values > 0)


c_title = "Net sentiment index"
c_subtitle = "Net sentiment (positive - negative words) vs average"
c_caption = "Source: FOMC Minutes, own calculations."
c_x_axis = ""
c_y_axis = "Sentiment index"



p <- ggplot(data = temp,
            mapping = aes(x = date, y = values, fill = change_positive))+
  geom_col() + guides(fill = FALSE) +
    theme_light()+
  #  theme_minimal(base_size=8)+
  theme(legend.position="bottom",
        plot.caption=element_text(hjust=0),
        plot.subtitle=element_text(face="italic"),
        plot.title=element_text(size=16,face="bold"))+
  labs(x=c_x_axis,y=c_y_axis,
       title=c_title,
       subtitle=c_subtitle,
       caption=c_caption)+
  scale_color_manual(values=c("#d73027","#4575b4"),name="Net sentiment Above/Below moving average sentiment")+
  scale_y_continuous(limits=c(-max(abs(temp$values)),max(abs(temp$values))))
p



```


```{r, echo=FALSE, messages=FALSE, warning=FALSE}



temp <- df %>%
  filter(category == "intensifiers")%>%
  filter(subject %in% c("intensifiers_net"))%>%
  filter(additional =="count_words")%>%
  
  #for plotting
  mutate(y_axis = ma_3m_share,
         x_axis = date,
         hline_intercept = avg_lt_share,
         fed_funds_rate = rate)



c_title = "Intensifier-index"
c_subtitle = "Intensifier-index shows the magnutide of positive and negative words (3m moving avg). \n Long term average in red, fed funds rate in blue (not fit to scale)."
c_caption = "Source: FOMC Minutes, own calculations. \nIntensifier-index calulates the difference between positive and negative words in combination with intensifiers."
c_x_axis = ""
c_y_axis = "Index"





p1 <- plot_line(temp, x_axis, y_axis, hline_intercept, fed_funds_rate, c_title, c_subtitle, c_caption, c_x_axis, c_y_axis)
p1


```




```{r, echo=FALSE, messages=FALSE, warning=FALSE}




temp <- df %>%
  filter(category == "sentiment_words")%>%
  filter(subject %in% c("Strong", "Weak", "Moderate"))%>%
  filter(additional =="count_words")%>%
  # as.data.frame(temp)%>%
  pivot_longer(-c("category", "subject", "additional", "date"), values_to = "values")%>%
  filter(name %in% c("ma_3m_share"))%>%
  #filter(name %in% c("frequency_share"))%>%
  select(date,subject, values)%>%
  pivot_wider(date, names_from = subject, values_from = values)%>%
  mutate(diff = (Strong-Weak)/Moderate)%>%
  mutate(average = mean(diff))%>%
  mutate(y_axis = diff,
         x_axis = date,
         hline_intercept = average)


##addera fed funds rate###
temp2 <- df %>%
  select(date, rate)%>%
  distinct(date,rate)

temp <- merge(temp,temp2,by.x = "date", all.x = TRUE)

temp <- temp %>%
  mutate(fed_funds_rate = rate)



c_title = "SWM-Index"
c_subtitle = "The use of words strong, weak and moderate in an index. \n Long term average in red, fed funds rate in blue (not fit to scale)."
c_caption = "Source: FOMC Minutes, own calculations. \nIndex: (Strong - weak) / moderate."
c_x_axis = ""
c_y_axis = "SWM-index"



p1 <- plot_line(temp, x_axis, y_axis, hline_intercept, fed_funds_rate, c_title, c_subtitle, c_caption, c_x_axis, c_y_axis)

p1
```



```{r, echo=FALSE, messages=FALSE, warning=FALSE}

temp <- df %>%
#  as.data.frame(temp)%>%
  filter(category == "sentiment_words")%>%
  filter(additional == "count_words")%>%
  filter(date == max(df$date))%>%
  select(subject, frequency_share, chg_avg_st_share, chg_avg_lt_share)%>%
  mutate(y_axis = chg_avg_st_share,
         x_axis = chg_avg_lt_share,
         bubble_size = frequency_share)


c_title = "Mapping Feds mind: selected sentiment indicators"
c_subtitle = "Topics current share compared to short and long term average"
c_caption = "Source: FOMC Minutes, own calculations."
c_x_axis = "Difference vs long term average"
c_y_axis = "Difference vs short term average"


p <- plot_bubble(temp, x_axis, y_axis, bubble_size, c_title, c_subtitle, c_caption, c_x_axis, c_y_axis)

p


```